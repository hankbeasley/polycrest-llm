{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\polycrest-llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n",
    "\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    RewardConfig,\n",
    "    RewardTrainer,\n",
    "    ScriptArguments,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    setup_chat_format,\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "from typing import List, Dict, Any\n",
    "from transformers import PreTrainedTokenizerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Hankbeasley/Polycrest-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"Hankbeasley/polycoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SystemPrompt>\n",
      "  <Overview>\n",
      "    You are a code-generation assistant designed to help users create high-quality, efficient, and well-documented code. You have access to various tools to aid in code analysis, debugging, and generation.\n",
      "  </Overview>\n",
      "  <Instructions>\n",
      "    <Instruction>Provide accurate and efficient code solutions tailored to the user's problem.</Instruction>\n",
      "    <Instruction>Follow best coding practices and include clear, helpful comments within the code.</Instruction>\n",
      "    <Instruction>Explain code logic and structure clearly when requested.</Instruction>\n",
      "    <Instruction>Leverage available tools to validate, analyze, and optimize code when applicable.</Instruction>\n",
      "  </Instructions>\n",
      "  <Capabilities>\n",
      "    <Capability>Generate code in multiple programming languages</Capability>\n",
      "    <Capability>Offer detailed explanations and documentation for code snippets</Capability>\n",
      "    <Capability>Assist with debugging and code optimization</Capability>\n",
      "    <Capability>Utilize integrated tools for code analysis and testing</Capability>\n",
      "  </Capabilities>\n",
      "  <Behavior>\n",
      "    <BehaviorInstruction>Ensure that all code adheres to modern coding standards and is well-structured.</BehaviorInstruction>\n",
      "  </Behavior>\n",
      "  <SystemInformation>\n",
      "    <OperatingSystem>win32</OperatingSystem>\n",
      "  </SystemInformation>\n",
      "</SystemPrompt>\n",
      "<Tools>\n",
      "You must response using one of these tools. Anything outside of these tools will not be processed. After you use the tool to modify the file the code will be tested and a response returned.\n",
      "Answer in JSON using this schema:\n",
      "{\n",
      "  reason: string,\n",
      "  tool: {\n",
      "    // Request to write full content to a file at the specified path. If the file exists, it will be overwritten with the provided content. If the file doesn't exist, it will be created. This tool will automatically create any directories needed to write the file.\n",
      "    tool_name: \"write_to_file\",\n",
      "    path: string,\n",
      "    content: string,\n",
      "  } or {\n",
      "    // Request to perform a replace operations on a file. You need to provide the path to the file and the start and end line of each replacement.\n",
      "    tool_name: \"replace\",\n",
      "    path: string,\n",
      "    operations: [\n",
      "      {\n",
      "        // The replacement text to use.\n",
      "        replace: string,\n",
      "        // The line number to start the replacement.\n",
      "        start_line: int,\n",
      "        // The line number to end the replacement. If not provided, it will end at the last line of the file.\n",
      "        end_line: int or null,\n",
      "      }\n",
      "    ],\n",
      "  },\n",
      "}\n",
      "</Tools><｜User｜><UserRequest>\n",
      "  <Request># Instructions\n",
      "\n",
      "Given an alphametics puzzle, find the correct solution.\n",
      "\n",
      "[Alphametics][alphametics] is a puzzle where letters in words are replaced with numbers.\n",
      "\n",
      "For example `SEND + MORE = MONEY`:\n",
      "\n",
      "```text\n",
      "  S E N D\n",
      "  M O R E +\n",
      "-----------\n",
      "M O N E Y\n",
      "```\n",
      "\n",
      "Replacing these with valid numbers gives:\n",
      "\n",
      "```text\n",
      "  9 5 6 7\n",
      "  1 0 8 5 +\n",
      "-----------\n",
      "1 0 6 5 2\n",
      "```\n",
      "\n",
      "This is correct because every letter is replaced by a different number and the words, translated into numbers, then make a valid sum.\n",
      "\n",
      "Each letter must represent a different digit, and the leading digit of a multi-digit number must not be zero.\n",
      "\n",
      "[alphametics]: https://en.wikipedia.org/wiki/Alphametics\n",
      "</Request>\n",
      "}\n",
      "<ReferencedFiles>\n",
      "  <Path>alphametics.js</Path><Content>1 | //\n",
      "2 | // This is only a SKELETON file for the 'Alphametics' exercise. It's been provided as a\n",
      "3 | // convenience to get you started writing code faster.\n",
      "4 | //\n",
      "5 | \n",
      "6 | export const solve = () => {\n",
      "7 |   throw new Error('Remove this statement and implement this function');\n",
      "8 | };\n",
      "9 | </Content>\n",
      "</ReferencedFiles>\n",
      "</UserRequest>\n",
      "  \n",
      "You Must Select a Tool To Use For the Next Step. Any text outside of the tools will not be processed or show to the user.<｜Assistant｜>\n"
     ]
    }
   ],
   "source": [
    "input = ds['train'][0]['accept'].split('<think>')[0]\n",
    "print(input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[151646,   3838,    646,    498,    653,     30, 151645, 151648]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "<｜begin▁of▁sentence｜>What can you do?<｜Assistant｜><think>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input2 = \"What can you do?<｜Assistant｜><think>\"\n",
    "tokens = tokenizer(input2, return_tensors=\"pt\").to('cuda')\n",
    "print(tokens)\n",
    "\n",
    "decoded = tokenizer.decode(tokens['input_ids'][0])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",  \n",
    "    torch_dtype=torch.bfloat16\n",
    "\n",
    ").to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelO = AutoModelForCausalLM.from_pretrained(\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    device_map=\"auto\",  \n",
    "    torch_dtype=torch.bfloat16\n",
    "\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can you do?<｜Assistant｜><think>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What’s\n",
      "\n",
      "-\n",
      "\n",
      "Do you\n",
      "\n",
      "-\n",
      "\n",
      "Think\n",
      "\n",
      "-\n",
      "\n",
      "Or\n",
      "\n",
      "-\n",
      "\n",
      "Do\n",
      "\n",
      "you\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n",
      "\n",
      "you\n",
      "\n",
      "can\n",
      "\n",
      "think\n",
      "\n",
      "that\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a=model.generate(tokens['input_ids'],  max_length=7000, pad_token_id=tokenizer.eos_token_id)\n",
    "#print(a)\n",
    "decoded = tokenizer.batch_decode(a, skip_special_tokens=True)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the streamer\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "\n",
    "# Start a thread to generate predictions\n",
    "generation_thread = Thread(target=model.generate, args=(tokens['input_ids'],), kwargs={'streamer': streamer})\n",
    "generation_thread.start()\n",
    "\n",
    "# Stream the output\n",
    "for new_text in streamer:\n",
    "    # Initialize the streamer\n",
    "    streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True)\n",
    "\n",
    "    # Start a thread to generate predictions\n",
    "    generation_thread = Thread(\n",
    "        target=model.generate,\n",
    "        args=(tokens['input_ids'],),\n",
    "        kwargs={\n",
    "            'attention_mask': tokens['attention_mask'],\n",
    "            'streamer': streamer,\n",
    "            'pad_token_id': tokenizer.eos_token_id\n",
    "        }\n",
    "    )\n",
    "    generation_thread.start()\n",
    "\n",
    "    # Stream the output\n",
    "    for new_text in streamer:\n",
    "        print(new_text, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
